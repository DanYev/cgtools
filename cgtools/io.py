import os
import numpy as np
import pandas as pd
from pathlib import Path
from cgtools.utils import timeit, memprofit, logger

################################################################################
## Reading trajectories with MDAnalysis
################################################################################  


def in_range(ts, b, e): # Check if ts.time is within the range (b, e)
    return b < ts.time < e


@timeit
@memprofit
def read_positions(u, atoms, b=0, e=10000000, sample_rate=1, dtype=np.float32):
    logger.info("Reading positions...")
    arr = np.array(
        [atoms.positions.flatten() for ts in u.trajectory[::sample_rate] if in_range(ts, b, e)], dtype=dtype)
    arr = np.ascontiguousarray(arr.T)  # Transpose for memory efficiency (shape: (n_coords, n_frames))
    logger.info("Done!")
    return arr


def read_velocities(u, atoms, b=0, e=10000000, sample_rate=1, dtype=np.float32):
    logger.info("Reading velocities...")
    arr = np.array(
        [atoms.velocities.flatten() for ts in u.trajectory[::sample_rate] if in_range(ts, b, e)], dtype=dtype)
    arr = np.ascontiguousarray(arr.T)  # Transpose for memory efficiency (shape: (n_coords, n_frames))
    logger.info("Done!")
    return arr


def parse_covar_dat(file, dtype=np.float32):
    """
    Reads covar.dat file generated by GROMACS
    """
    df = pd.read_csv(file, sep='\\s+', header=None)
    covariance_matrix = np.asarray(df, dtype=dtype)
    resnum = int(np.sqrt(len(covariance_matrix) / 3))
    covariance_matrix = np.reshape(covariance_matrix, (3*resnum, 3*resnum))
    return covariance_matrix


def fname_filter(f, sw='', cont='', ew=''):  
    """
    Filters a file name based on its start, substring, and end patterns.
    """
    return f.startswith(sw) and cont in f and f.endswith(ew)
    

def filter_files(fpaths, sw='', cont='', ew=''):  
    """
    Filters files in a list using the above filter
    """
    files = [f for f in fpaths if fname_filter(f.name, sw=sw, cont=cont, ew=ew)]
    return files
    

def pull_files(directory, pattern):
    """
    Recursively lists all files in the given directory and its subdirectories.
    Parameters: directory (str or Path): The root directory to start searching for files.
    Returns: list[str]: A list of string, each representing the absolute path
            to a file within the directory and its subdirectories.
    """
    # rglob will recursively search for files matching the pattern
    base_path = Path(directory)
    if not base_path.exists() or not base_path.is_dir():
        raise FileNotFoundError(f"Directory '{directory}' does not exist or is not a directory.")
    return [str(p) for p in base_path.rglob(pattern)]


def pull_all_files(directory):
    return pull_files(directory, pattern='*')


def read_data(fpath):
    """ 
    Reads a .csv or .npy file 
    Input 
    ------
    fname: string
        Name of the file to read
    Output 
    ------
    data: ndarray
        Numpy array
    """
    ftype = fpath.split('.')[-1]
    if ftype == 'npy':
        try:
            data = np.load(fpath)
        except:
            raise ValueError()
    if ftype == 'csv' or ftype == 'dat':
        try:
            df = pd.read_csv(fpath, sep='\\s+', header=None)
            data = df.values
            data = np.squeeze(df.values)
            if data.shape[0] != 1104:
                raise ValueError()
        except:
            raise ValueError()
    if ftype == 'xvg':
        try:
            df = pd.read_csv(fpath, sep='\\s+', header=None, usecols=[1])
            data = df.values
            data = np.squeeze(df.values)
            if data.shape[0] > 10000:
                raise ValueError()
        except:
            raise ValueError()
    return data
    
    
def read_xvg(fpath, usecols=[0, 1]):
    """ 
    Reads a GROMACS xvg file
    
    Input 
    ------
    fname: string
        Name of the file to read
    Output 
    ------
    data: ndarray
        Numpy array
    """
    try:
        df = pd.read_csv(fpath, sep='\\s+', header=None, usecols=usecols)
        data = df
    except:
        raise ValueError()
    return data
    
    
def save_data(data, fpath):
    """ 
    Saves the data as a .csv or .npy file 
    
    Input 
    ------
    data: numpy array
        Numpy array of data
    fpath: string
        Path to the file to save
    Output 
    ------
    """
    ftype = fpath.split('.')[-1]
    if ftype == 'npy':
        np.save(fpath, data)
    if ftype == 'csv':
        df = pd.DataFrame(data)
        df.to_csv(fpath, index=False, header=None, float_format='%.3E', sep=',')
        
        
def calc_mean_sem(datas):
    datas = np.array(datas)
    mean = np.average(datas, axis=0)
    sem = np.std(datas, axis=0) / np.sqrt(datas.shape[0])
    return mean, sem


def save_1d_data(data, ids=[], fpath='dfi.xvg', sep=' '): 
    """ 
    Saves 1d data like DFI in the GROMACS's .xvg format
    Input: 
    data: list or numpy array
        y-column
    ids: list or numpy array
        x-column
    fpath: string
        Path to the file to save
    ------
    """
    ids = list(ids)
    if not ids:
        ids = np.arange(1, len(data)+1).astype(int)
    df = pd.DataFrame({'ids': ids, 'data': data})
    df.to_csv(fpath, index=False, header=None, float_format='%.3E', sep=sep)
    
    
def save_2d_data(data, ids=[], fpath='dfi.xvg', sep=' '): 
    """ 
    Saves 2d data like group-group DCI in the GROMACS's .xvg format
    Input: 
    data: list or numpy array
    fpath: string
        Path to the file to save
    ------
    """
    df = pd.DataFrame(data)
    df.to_csv(fpath, index=False, header=None, float_format='%.3E', sep=sep)
        